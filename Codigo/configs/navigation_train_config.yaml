# REACTIVE NAVIGATION
# Train configuration
# Developed by Luna Jimenez Fernandez
#
# This file is used to specify the configuration of agents during training
# Thus, it includes info related to training (such as rewards)
#
# NOTE: Some of the arguments are not included in the config file, since
# they are instead passed as arguments by the user.
# These arguments will still be specified in the code with comment blocks



# ENVIRONMENT: Max Steps are specified via arguments
#ENVIRONMENT:
#  MAX_EPISODE_STEPS:

SIMULATOR:
  AGENT_0:
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
  RGB_SENSOR:
    WIDTH: 256
    HEIGHT: 256
  DEPTH_SENSOR:
    WIDTH: 256
    HEIGHT: 256

# DATASET: Data path and split are specified via argument
DATASET:
  TYPE: PointNav-v1
#  SPLIT:
#  DATA_PATH:

# TASK: Success distance is specified via argument
TASK:
  TYPE: Nav-v0
#  SUCCESS_DISTANCE: 
  SENSORS: ['POINTGOAL_WITH_GPS_COMPASS_SENSOR']
  POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT']
  POINTGOAL_WITH_GPS_COMPASS_SENSOR:
    GOAL_FORMAT: "POLAR"
    DIMENSIONALITY: 2
  GOAL_SENSOR_UUID: pointgoal_with_gps_compass
  MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
  # SUCCESS:
    # SUCCESS_DISTANCE:
    
TRAINER:
  RL:
    SUCCESS_REWARD: 10.0
    SLACK_REWARD: -0.01

